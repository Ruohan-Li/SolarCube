{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f74be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 16:03:20.111201: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2024-04-29 16:03:20.124203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:2f:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-04-29 16:03:20.125168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-04-29 16:03:20.212929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2024-04-29 16:03:20.267524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2024-04-29 16:03:20.309089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2024-04-29 16:03:20.331102: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-04-29 16:03:20.375333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-04-29 16:03:20.397957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-04-29 16:03:20.399339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "CUDA_VISIBLE_DEVICES=0\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num GPUs Available: \", tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "import io\n",
    "import os\n",
    "import pickle\n",
    "import h5py\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, ConvLSTM2D, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from solarsat.utils import SolarSatSequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a836c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/data1/lianggp/lir/solar_data/process_results/solarsat_cnnlstm/logs/20240429_160332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 16:03:32.412470: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2024-04-29 16:03:32.421363: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz\n",
      "2024-04-29 16:03:32.423381: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562d015a52b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-29 16:03:32.423403: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-04-29 16:03:32.424329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:2f:00.0 name: Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2024-04-29 16:03:32.424374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-04-29 16:03:32.424387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2024-04-29 16:03:32.424399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2024-04-29 16:03:32.424410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2024-04-29 16:03:32.424421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-04-29 16:03:32.424432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-04-29 16:03:32.424444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-04-29 16:03:32.425662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2024-04-29 16:03:32.425691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-04-29 16:03:32.527881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-04-29 16:03:32.527914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2024-04-29 16:03:32.527927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2024-04-29 16:03:32.529974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14771 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:2f:00.0, compute capability: 7.0)\n",
      "2024-04-29 16:03:32.531800: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562d01f044a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-29 16:03:32.531817: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tile  year  start_index\n",
      "0     h15v03  2018           60\n",
      "1     h15v03  2018           64\n",
      "2     h15v03  2018          156\n",
      "3     h15v03  2018          160\n",
      "4     h15v03  2018          252\n",
      "...      ...   ...          ...\n",
      "1791  h15v03  2018        34816\n",
      "1792  h15v03  2018        34908\n",
      "1793  h15v03  2018        34912\n",
      "1794  h15v03  2018        35004\n",
      "1795  h15v03  2018        35008\n",
      "\n",
      "[1796 rows x 3 columns]\n",
      "        tile  year  start_index\n",
      "0     h15v03  2018           60\n",
      "1     h15v03  2018           64\n",
      "2     h15v03  2018          156\n",
      "3     h15v03  2018          160\n",
      "4     h15v03  2018          252\n",
      "...      ...   ...          ...\n",
      "1791  h15v03  2018        34816\n",
      "1792  h15v03  2018        34908\n",
      "1793  h15v03  2018        34912\n",
      "1794  h15v03  2018        35004\n",
      "1795  h15v03  2018        35008\n",
      "\n",
      "[1796 rows x 3 columns]\n",
      "Loading training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:09<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "(40, 8, 30, 30)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 8, 30, 30, 1)\n",
      "Train on 40 samples, validate on 1 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 16:03:54.390907: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] layout failed: Invalid argument: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/sequential/conv_lst_m2d_1/while_grad/body/_1098/input/_2220' -> 'sequential/conv_lst_m2d_1/while_grad/body/_1098/gradients/AddN', 'Func/sequential/conv_lst_m2d/while_grad/body/_1289/input/_2336' -> 'sequential/conv_lst_m2d/while_grad/body/_1289/gradients/AddN', 'Func/sequential/conv_lst_m2d_2/while_grad/body/_907/input/_2104' -> 'sequential/conv_lst_m2d_2/while_grad/body/_907/gradients/AddN', 'Func/sequential/conv_lst_m2d_3/while_grad/body/_717/input/_1988' -> 'sequential/conv_lst_m2d_3/while_grad/body/_717/gradients/AddN', 'sequential/conv_lst_m2d_3/while/body/_538/mul_5' -> 'sequential/conv_lst_m2d_3/while/body/_538/Identity_4', 'sequential/conv_lst_m2d_3/while/body/_538/mul_2' -> 'sequential/conv_lst_m2d_3/while/body/_538/add_5', 'sequential/conv_lst_m2d_2/while/body/_359/mul_5' -> 'sequential/conv_lst_m2d_2/while/body/_359/Identity_4', 'sequential/conv_lst_m2d_2/while/body/_359/mul_2' -> 'sequential/conv_lst_m2d_2/while/body/_359/add_5', 'sequential/conv_lst_m2d_1/while/body/_180/mul_2' -> 'sequential/conv_lst_m2d_1/while/body/_180/add_5', 'sequential/conv_lst_m2d_1/while/body/_180/mul_5' -> 'sequential/conv_lst_m2d_1/while/body/_180/Identity_4', 'Func/sequential/conv_lst_m2d/while/body/_1/input/_1525' -> 'sequential/conv_lst_m2d/while/body/_1/mul_2', 'sequential/conv_lst_m2d/while/body/_1/mul_5' -> 'sequential/conv_lst_m2d/while/body/_1/Identity_4'}.\n",
      "2024-04-29 16:03:55.700579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-04-29 16:04:00.401996: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Not found: ./bin/ptxas not found\n",
      "Relying on driver to perform ptx compilation. This message will be only logged once.\n",
      "2024-04-29 16:04:00.435323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/40 [============================>.] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 16:04:04.134717: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] layout failed: Invalid argument: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/sequential/conv_lst_m2d_3/while/body/_148/input/_330' -> 'sequential/conv_lst_m2d_3/while/body/_148/mul_2', 'sequential/conv_lst_m2d_3/while/body/_148/Identity_4' -> 'sequential/conv_lst_m2d_3/while/next_iteration/_192', 'sequential/conv_lst_m2d_2/while/body/_99/Identity_4' -> 'sequential/conv_lst_m2d_2/while/next_iteration/_143', 'Func/sequential/conv_lst_m2d_2/while/body/_99/input/_292' -> 'sequential/conv_lst_m2d_2/while/body/_99/mul_2', 'sequential/conv_lst_m2d_1/while/body/_50/Identity_4' -> 'sequential/conv_lst_m2d_1/while/next_iteration/_94', 'sequential/conv_lst_m2d_1/while/body/_50/mul_2' -> 'sequential/conv_lst_m2d_1/while/body/_50/add_5', 'sequential/conv_lst_m2d/while/body/_1/add_5' -> 'sequential/conv_lst_m2d/while/body/_1/Identity_5', 'sequential/conv_lst_m2d/while/body/_1/mul_3' -> 'sequential/conv_lst_m2d/while/body/_1/add_5', 'sequential/conv_lst_m2d/while/body/_1/clip_by_value_1' -> 'sequential/conv_lst_m2d/while/body/_1/mul_2', 'sequential/conv_lst_m2d/while/body/_1/clip_by_value_2' -> 'sequential/conv_lst_m2d/while/body/_1/mul_5'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 14s 349ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 2s 54ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 2s 53ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 2s 54ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 2s 54ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 2s 54ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 2s 55ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 2s 55ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 2s 54ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 2s 55ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 2s 55ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 2s 55ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 2s 55ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 2s 55ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 2s 53ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 2s 55ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 2s 57ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 2s 55ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 2s 55ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 2s 57ms/sample - loss: nan - val_loss: nan\n",
      "hhS\n"
     ]
    }
   ],
   "source": [
    "# from solarsat.display import get_cmap\n",
    "HOME_PATH = '/gpfs/data1/lianggp/lir/solar_data/process_results'\n",
    "# Set up callbacks\n",
    "datetag=datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "logdir = f'{HOME_PATH}/solarsat_cnnlstm/logs/' + datetag\n",
    "print(logdir)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_tstimg = tf.summary.create_file_writer(logdir+'/imgs')\n",
    "\n",
    "netsave_dir = f'{HOME_PATH}/solarsat_cnnlstm/trained_networks/'+datetag\n",
    "Path(netsave_dir).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "def CNNLSTM():\n",
    "    seq = Sequential()\n",
    "    seq.add(BatchNormalization())\n",
    "    seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                    input_shape=(None, 60,60, 1),\n",
    "                    padding='same', return_sequences=True))\n",
    "    seq.add(BatchNormalization())\n",
    "\n",
    "    seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                    padding='same', return_sequences=True))\n",
    "    seq.add(BatchNormalization())\n",
    "\n",
    "    seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                    padding='same', return_sequences=True))\n",
    "    seq.add(BatchNormalization())\n",
    "\n",
    "    seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                    padding='same', return_sequences=True))\n",
    "    seq.add(BatchNormalization())\n",
    "\n",
    "    seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "                activation='sigmoid',\n",
    "                padding='same', data_format='channels_last'))\n",
    "    seq.compile(loss='mse', optimizer='adadelta')\n",
    "    return seq\n",
    "    \n",
    "\n",
    "def main():\n",
    "    # args = parse_args()\n",
    "    x_trn,x_tst = load_datasets(n_batches_train=50,n_batches_test=10)  \n",
    "    print(len(x_trn))\n",
    "    print(len(x_trn[0]))\n",
    "    print(x_trn[0][0].shape)\n",
    "    \n",
    "    # if args.version=='1':\n",
    "    #     from sevir.models.vaes.classes import VAE_v1 as VAE\n",
    "    # elif args.version=='2':\n",
    "    #     from sevir.models.vaes.classes import VAE_v2 as VAE\n",
    "    cnnlstm = CNNLSTM()\n",
    "\n",
    "    # Callbacks\n",
    "    def predict(x):\n",
    "        yhat=cnnlstm.predict(x)\n",
    "        return yhat\n",
    "        # return SEVIRSequence.unnormalize(yhat,(1/255,0))\n",
    "    testimg_cb = tf.keras.callbacks.LambdaCallback(\n",
    "        on_epoch_end=partial(plot_test_images,x_test=x_tst[0],predict=predict) )\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(netsave_dir+'/weights.{epoch:02d}-{val_loss:.2f}.tf', \n",
    "                              monitor='val_loss', verbose=0, \n",
    "                              save_best_only=True, save_weights_only=False, \n",
    "                              mode='auto', period=1)\n",
    "    \n",
    "\n",
    "    x_trn_input = np.stack(x_trn[0], axis=-1)  # The new axis is the channel axis\n",
    "    x_tst_input = np.stack(x_tst[0], axis=-1)  # The new axis is the channel axis\n",
    "    print(x_trn_input.shape)\n",
    "\n",
    "    cnnlstm.fit(x_trn_input,x_trn_input,\n",
    "            epochs=20,\n",
    "            batch_size=1,\n",
    "            max_queue_size=10,\n",
    "            validation_data=(x_tst_input,x_tst_input),\n",
    "            workers=5,\n",
    "            verbose=1,\n",
    "            use_multiprocessing=True,\n",
    "            # callbacks=[tensorboard_callback,\n",
    "            #           testimg_cb,\n",
    "            #           checkpoint_cb]\n",
    "            )\n",
    "\n",
    "\n",
    "def load_generators():\n",
    "    # # date ranges for train/test\n",
    "    # train_dates = (datetime(2018,1,1),datetime(2019,6,1))\n",
    "    # test_dates  = (datetime(2019,6,1),datetime(2020,1,1))\n",
    "\n",
    "    # Generate single images of weather radar echos\n",
    "    trn_gen_file='/tmp/trn_gen.pkl'\n",
    "    if not os.path.exists(trn_gen_file):\n",
    "        data_gen_trn = SolarSatSequence(x_img_types=['ssr'],y_img_types=['ssr'],\n",
    "                                     batch_size=2,\n",
    "                                     n_batch_per_epoch=20,\n",
    "                                     unwrap_time=True, # don't generate sequences\n",
    "                                     shuffle=True,\n",
    "                                    #  start_date=train_dates[0],\n",
    "                                    #  end_date=train_dates[1],\n",
    "                                    #  normalize_x=[(1/255,0)]\n",
    "                                    )\n",
    "        # data_gen_trn.save(trn_gen_file)\n",
    "    else:\n",
    "        data_gen_trn = SolarSatSequence.load(trn_gen_file)\n",
    "\n",
    "    tst_gen_file='/tmp/tst_gen.pkl'\n",
    "    if not os.path.exists(tst_gen_file):\n",
    "        data_gen_tst = SolarSatSequence(x_img_types=['ssr'],y_img_types=['ssr'],\n",
    "                                     batch_size=1,\n",
    "                                     n_batch_per_epoch=1,\n",
    "                                     unwrap_time=True, # don't generate sequences\n",
    "                                     shuffle=True,\n",
    "                                    #  start_date=train_dates[0],\n",
    "                                    #  end_date=train_dates[1],\n",
    "                                    #  normalize_x=[(1/255,0)]\n",
    "                                    )\n",
    "        # data_gen_tst.save(tst_gen_file)\n",
    "    else:\n",
    "        data_gen_tst = SolarSatSequence.load(tst_gen_file)\n",
    "\n",
    "    return data_gen_trn,data_gen_tst\n",
    "\n",
    "\n",
    "def load_datasets(n_batches_train=100,n_batches_test=50):\n",
    "    \n",
    "    trn_data_name = f'{HOME_PATH}/data'\n",
    "    if not os.path.exists(trn_data_name):\n",
    "        os.mkdir(trn_data_name)\n",
    "    trn_data_name+='/solarsat_cnnlstm_train.h5'\n",
    "    # if not os.path.exists(trn_data_name):\n",
    "    #     # make it\n",
    "    #     data_gen_trn,data_gen_tst = load_generators()\n",
    "    #     print('Loading training data')\n",
    "    #     x_train = data_gen_trn.load_batches(n_batches=n_batches_train,progress_bar=True)\n",
    "    #     # print(x_train.shape)\n",
    "    #     print('Loading test data')\n",
    "    #     x_test = data_gen_tst.load_batches(n_batches=n_batches_test,progress_bar=True)\n",
    "    #     with h5py.File(trn_data_name,'w') as hf:\n",
    "    #         hf.create_dataset(\"TRAIN\",data=x_train)\n",
    "    #         hf.create_dataset(\"TEST\",data=x_test)\n",
    "    # else:\n",
    "    #     with h5py.File(trn_data_name,'r') as hf:\n",
    "    #         x_train = hf['TRAIN'][:]\n",
    "    #         x_test = hf['TEST'][:]\n",
    "\n",
    "\n",
    "    # make it\n",
    "    data_gen_trn,data_gen_tst = load_generators()\n",
    "    print('Loading training data')\n",
    "    x_train = data_gen_trn.load_batches(n_batches=n_batches_train,progress_bar=True)\n",
    "    # print(x_train.shape)\n",
    "    print('Loading test data')\n",
    "    x_test = data_gen_tst.load_batches(n_batches=n_batches_test,progress_bar=True)\n",
    "    # print(len(x_train))\n",
    "\n",
    "    return x_train,x_test\n",
    "\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "def plot_test_images(epoch,logs,x_test,predict):\n",
    "    # cmap,norm,vmin,vmax = get_cmap('vil')\n",
    "    fig,axs = plt.subplots(3,6,figsize=(15,10))\n",
    "    np.random.seed(seed=2)\n",
    "    idx = np.random.choice( x_test[0].shape[0],9)\n",
    "    ii=0\n",
    "    yhat=predict(x_test[0][idx])\n",
    "    for i in range(3):\n",
    "        for j in range(0,6,2):\n",
    "            # xx=SEVIRSequence.unnormalize(x_test[0][idx[ii],:,:,0],(1/255,0))\n",
    "            xx=x_test[0][idx[ii],:,:,0]\n",
    "            # axs[i][j].imshow(xx,cmap=cmap,norm=norm,vmin=vmin,vmax=vmax)\n",
    "            axs[i][j].imshow(xx)\n",
    "            axs[i][j].set_xticks([], []), axs[i][j].set_yticks([], [])\n",
    "            axs[i][j].set_xlabel('Original Image')\n",
    "            # axs[i][j+1].imshow(yhat[ii,:,:,0],cmap=cmap,norm=norm,vmin=vmin,vmax=vmax)\n",
    "            axs[i][j+1].imshow(yhat[ii,:,:,0])\n",
    "            axs[i][j+1].set_xticks([], []), axs[i][j+1].set_yticks([], [])\n",
    "            axs[i][j+1].set_xlabel('Decoded Image')\n",
    "            ii+=1\n",
    "    tst_images = plot_to_image(fig)\n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_tstimg.as_default():\n",
    "        tf.summary.image(\"CNNLSTM Test Images\", tst_images, step=epoch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "    print('hhS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0721399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
